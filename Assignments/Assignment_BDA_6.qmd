---
title: "Assignment 6"
author: anonymous # <-- hand in anonymously
format: 
  html:
    toc: true
    code-tools: true
    code-line-numbers: true  
    number-sections: true
    mainfont: Georgia, serif
    page-layout: article
  pdf:  
    geometry:
    - left=1cm,top=1cm,bottom=1cm,right=7cm
    number-sections: true
    code-annotations: none
editor: source

---

# Assignment 1


::: {.content-hidden when-format="pdf"}
::: {.callout-warning collapse="false"}
## Setup

*This block will only be visible in your HTML output, but will be hidden when rendering to PDF with quarto for the submission.* **Make sure that this does not get displayed in the PDF!**

JupyterHub has all the needed packages pre-installed.

The following installs and loads the `aaltobda` package:

```{r}
if(!require(aaltobda)){
    install.packages("remotes")
    remotes::install_github("avehtari/BDA_course_Aalto", subdir = "rpackage", upgrade="never")
    library(aaltobda)
}
```

The following installs and loads the [`latex2exp` package](https://github.com/stefano-meschiari/latex2exp), which allows us to use LaTeX in plots:

```{r}
if(!require(latex2exp)){
    install.packages("latex2exp")
    library(latex2exp)
}
```

The following installs and loads the [`posterior` package](https://github.com/stan-dev/posterior) which imports the `rhat_basic()` function:

```{r}
if(!require(posterior)){
    install.packages("posterior")
    library(posterior)
}
```

The following installs and loads the [`ggplot2` package](https://ggplot2.tidyverse.org/), the [`bayesplot` package](https://mc-stan.org/bayesplot/index.html) and the [`dplyr` package](https://dplyr.tidyverse.org/)

```{r}
if(!require(ggplot2)){
    install.packages("ggplot2")
    library(ggplot2)
}
if(!require(bayesplot)){
    install.packages("bayesplot")
    library(bayesplot)
}
if(!require(dplyr)){
    install.packages("dplyr")
    library(dplyr)
}
if(!require(tidyr)){
    install.packages("tidyr")
    library(tidyr)
}
# Some additional set-up to make plots legible
ggplot2::theme_set(theme_minimal(base_size = 14))
bayesplot::bayesplot_theme_set(theme_minimal(base_size = 14))
# register_knitr_engine()
```

The following installs and loads the [`cmdstanr` package](https://mc-stan.org/cmdstanr/) and tries to install `cmdstan`.

```{r}
if(!require(cmdstanr)){
    install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
    library(cmdstanr)
}
cmdstan_installed <- function(){
  res <- try(out <- cmdstanr::cmdstan_path(), silent = TRUE)
  !inherits(res, "try-error")
}
if(!cmdstan_installed()){
    install_cmdstan()
}
```
:::
:::

::: {.content-hidden when-format="pdf"}
::: {.callout-warning collapse="false"}
# Subtask 2.a

```{r}
library(rstan)
a = stanc("linear_model.stan")

```

## Data preparation and sampling from the posterior

*This block will only be visible in your HTML output, but will be hidden when rendering to PDF with quarto for the submission.* **Make sure that this does not get displayed in the PDF!**

**Data assembly happens here**:

```{r}
#| warning: false
# These are our observations y: the proportion of students handing in each assignment (1-8),
# sorted by year (row-wise) and assignment (column-wise).
# While the code suggest a matrix structure, 
# the result will actually be a vector of length N = no_years * no_assignments
propstudents<-c(c(176, 174, 158, 135, 138, 129, 126, 123)/176,
                c(242, 212, 184, 177, 174, 172, 163, 156)/242,
                c(332, 310, 278, 258, 243, 242, 226, 224)/332,
                c(301, 269, 231, 232, 217, 208, 193, 191)/301,
                c(245, 240, 228, 217, 206, 199, 191, 182)/245)
# These are our predictors x: for each observation, the corresponding assignment number.
assignment <- rep(1:8, 5)
# These are in some sense our test data: the proportion of students handing in the last assignment (9),
# sorted by year. 
# Usually, we would not want to split our data like that and instead
# use e.g. Leave-One-Out Cross-Validation (LOO-CV, see e.g. http://mc-stan.org/loo/index.html)
# to evaluate model performance.
propstudents9 = c(121/176, 153/242, 218/332, 190/301, 175/245)
# The total number of assignments
no_assignments = 9
# The assignment numbers for which we want to generate predictions
x_predictions = 1:no_assignments
# (Cmd)Stan(R) expects the data to be passed in the below format:
model_data = list(N=length(assignment),
                 x=assignment,
                 y=propstudents,
                 no_predictions=no_assignments,
                 x_predictions=x_predictions)
```

**Sampling from the posterior distribution happens here**:

```{r}
#| warning: false 
# This reads the file at the specified path and tries to compile it. 
# If it fails, an error is thrown.
retention_model = cmdstan_model("linear_model.stan")
# This "out <- capture.output(...)" construction suppresses output from cmdstanr
# See also https://github.com/stan-dev/cmdstanr/issues/646
out <- capture.output(
    # Sampling from the posterior distribution happens here:
    fit <- retention_model$sample(data=model_data, refresh=0, show_messages=FALSE)
)
```

**Draws postprocessing happens here**:

```{r}

# This extracts the draws from the sampling result as a data.frame.
draws_df = fit$draws(format="draws_df")

# This does some data/draws wrangling to compute the 5, 50 and 95 percentiles of 
# the mean at the specified covariate values (x_predictions). 
# It can be instructive to play around with each of the data processing steps
# to find out what each step does, e.g. by removing parts from the back like "|>  gather(pct,y,-x)"
# and printing the resulting data.frame.
mu_quantiles_df = draws_df |> 
      subset_draws(variable = c("mu_pred")) |> 
      summarise_draws(~quantile2(.x, probs = c(0.05, .5, 0.95))) |> 
      mutate(x = 1:9) |> 
      pivot_longer(c(q5, q50, q95), names_to = c("pct"))

# Same as above, but for the predictions.
y_quantiles_df = draws_df |> 
      subset_draws(variable = c("y_pred")) |> 
      summarise_draws(~quantile2(.x, probs = c(0.05, .5, 0.95))) |> 
      mutate(x = 1:9) |> 
      pivot_longer(c(q5, q50, q95), names_to = c("pct"))
```
:::
:::

::: both
## Fixed linear model
![Alt Text](Linear_model.png)


Changed the following three syntax errors:

-   Row 20: "real\<upper=0\> sigma" -\> "real\<lower=0\> sigma" to ensure that the standard deviation is constrained to be positive.
-   Row 25: Adding a semicolon at the end of vector\[N\] mu = alpha + beta \* x;.
-   Row 38-39:In the generated quantities block, I replaced array\[no_predictions\] real y_pred with vector\[no_predictions\] y_pred and corrected the sampling loop to compute y_pred correctly.



**Plotting happens here**:

```{r}
#| label: fig-posterior
#| fig-cap: Describe me in your submission!
ggplot() +
  # scatter plot of the training data:  
  geom_point(
    aes(x, y, color=assignment), 
    data=data.frame(x=assignment, y=propstudents, assignment="1-8")
) +
  # scatter plot of the test data:
  geom_point(
    aes(x, y, color=assignment), 
    data=data.frame(x=no_assignments, y=propstudents9, assignment="9")
) +
  # you have to tell us what this plots:
  geom_line(aes(x,y=value,linetype=pct), data=mu_quantiles_df, color='grey', linewidth=1.5) +
  # you have to tell us what this plots:
  geom_line(aes(x,y=value,linetype=pct), data=y_quantiles_df, color='red') +
  # adding xticks for each assignment:
  scale_x_continuous(breaks=1:no_assignments) +
  # adding labels to the plot:
  labs(y="assignment submission %", x="assignment number") +
  # specifying that line types repeat:
  scale_linetype_manual(values=c(2,1,2)) +
  # Specify colours of the observations:
  scale_colour_manual(values = c("1-8"="black", "9"="blue")) +
  # remove the legend for the linetypes:
  guides(linetype="none")
```


The grey lines represent the mu_pred which is the expected quantiles (5%, 50% and 95%) of the covariants (x predictions). This is computed by \$\mu\_{pred} = \alpha + \beta \* x \$. The dashed lines are the 5% and 95% quantiles while the middle line is the mean.

The red lines represent the posterior distribution which are sampled from a normal distribution with mean given by mu_pred and standard deviation given by sigma. The dashed lines are the 5% and 95% quantiles while the middle line is the mean.

The difference between the red and grey lines, is that red lines use expected values as grey use expected values with incorporating uncertanty around these scpectations.

The student retention rate is represented by a downward linear slope with fewer submissions in the later weeks relativly to the older weeks. The rationale behind this phenomenon lies in is simply that students who start do not finnish the course. Why? This is more speculation and outside of the scope of this course.

The preditive power is not satisfactory with a range of about 10 percentages points but, only 1/5 points is inside the grey dashed lines and 3/5 point inside the red dashed lines.

Improving the model: - Add regularisation to the model to avoid overfit with Ridge or Lasso - Use Informed prioris based on domain knowledge - Try a different model

```{r}
fit$cmdstan_diagnose()
```

:::

::: {.content-hidden when-format="pdf"}
::: {.callout-warning collapse="false"}
## Quick check for sampling convergence

*This block will only be visible in your HTML output, but will be hidden when rendering to PDF with quarto for the submission.* **Make sure that this does not get displayed in the PDF!**

If your model is correctly implemented, sampling from the posterior distribution should have been successful. You can check whether Stan thinks that sampling succeeded by inspecting the output of the below command, which you should be able to interpret with a little help from the [CmdStan User's Guide](https://mc-stan.org/docs/cmdstan-guide/diagnose.html).


:::
:::

# Assignment 2
## Code for "multi_normal_model.stan"

![Multi_normal_model](Multi_nomral_model.png)

```{r, results='hide'}
data("bioassay")

model = cmdstan_model("multi_normal_model.stan")

mu_a <- 0  # Mean of the first variable
mu_b <- 10  # Mean of the second variable
sigma_a <- 2  # Standard deviation of the first variable
sigma_b <- 10  # Standard deviation of the second variable
rho <- 0.6  # Correlation coefficient

cov_matrix <- matrix(c(sigma_a^2, rho * sigma_a * sigma_b, rho * sigma_a * sigma_b, sigma_b^2), nrow = 2, ncol = 2)
mean_vector <- c(mu_a, mu_b)

data_list <- list(
  N = length(bioassay$x),
  x = bioassay$x,
  y =   bioassay$y,
  n = bioassay$n,
  mu = mean_vector,
  Sigma = cov_matrix
)

fit <- stan(file = "multi_normal_model.stan", data = data_list, chains = 4, iter = 2000)

```

```{r}
print(fit)
```


```{r}
theta_samples <- as.data.frame(fit, pars = "theta")

colnames(theta_samples) <- c("Alpha","Beta")
print(paste("R_hat for Alpha", round(rhat_basic(theta_samples["Alpha"]), digits=4)))
print(paste("R_hat for Beta", round(rhat_basic(theta_samples["Beta"]), digits=4)))
```

## Interpetaion of R_hat

R_hat helps determine whether multiple chains have convereged and whether the MCMC sampler has adequately explored the target distribution. Common practice is to consider chains converged if R_hat \< 1.05. The Rhat for alpha (Theta\[1\] in code) is 1 and beta (Theta\[2\]in code) is 1. Same values confirmed with with rhat_baisc() and fit\$summary()

```{r}

# Create a scatter plot
ggplot(theta_samples, aes(x = Alpha, y = Beta)) +
  geom_point() +
  labs(x = "Alpha", y = "Beta") +
  ggtitle("Scatter Plot of Theta Values")

```

## Scatter plot about draws

The scatter plot looks similar to the one made in Assignment 5.

## Stan setup

-   Operating system mac os
-   programming eviroment: R
-   Interference used: RStan and CmdStanR
-   Installed locally. I had some minior porblem but was able to get everything running in 10 min
-   Debugging in Stan is not fun for exapmle syntax change about arrays was frustrating. Not a lot of resources out for example youtube videos. Stans own documation is actually the best resource wish I had just started with it.

## AI usage

In this assignment chatgpt was used to learn stan, help with debugging in stan and better formulate assignments
